{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 In-Class\n",
    "\n",
    "Today, we'll be working with *existing* implementations of the ML Classification approaches we've discussed so far (KNN, Naive Bayes, Logistic Regression). We're going to explore manipulating the various optimization features.\n",
    "\n",
    "## Your objective: Identifying the stability of an electrical grid\n",
    "\n",
    "Description of the dataset: https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+\n",
    "\n",
    "(We excluded the raw output variable)\n",
    "\n",
    "Your objective: Get the highest accuracy score you can, on any classifier, by manipulating the input to the classifier (either 1. editing the arguments to the classifier itself (e.g. the number of neighbors for KNN) or 2. scaling the training and testing features (e.g. the 0 - 1 scaling we discussed in class). \n",
    "\n",
    "## Documentation\n",
    "\n",
    "KNN - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "NB - https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "\n",
    "LR - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Scaling options\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier\n",
      "0.777\n",
      "Naive Bayes Classifier\n",
      "0.8145\n",
      "Logistic Regression\n",
      "0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavgs/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  app.launch_new_instance()\n",
      "/Users/pranavgs/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/pranavgs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/pranavgs/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "trainFeatures = np.array(list(csv.reader(open('./GridStabilityTrainFeatures.csv', 'r'), delimiter=','))).astype('float')\n",
    "trainResults = np.array(list(csv.reader(open('./GridStabilityTrainResults.csv', 'r'), delimiter=',')))\n",
    "testFeatures = np.array(list(csv.reader(open('./GridStabilityTestFeatures.csv', 'r'), delimiter=','))).astype('float')\n",
    "testResults = np.array(list(csv.reader(open('./GridStabilityTestResults.csv', 'r'), delimiter=',')))\n",
    "\n",
    "\n",
    "print(\"KNN Classifier\")\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "knn.fit(trainFeatures, trainResults)\n",
    "print(knn.score(testFeatures, testResults))\n",
    "\n",
    "print(\"Naive Bayes Classifier\")\n",
    "nb = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "nb.fit(trainFeatures, trainResults)\n",
    "print(nb.score(testFeatures, testResults))\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "lr = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
    "lr.fit(trainFeatures, trainResults)\n",
    "print(lr.score(testFeatures, testResults))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
